{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Machine Learning Classifiers: Evaluate Random Forest with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid-search:** Exhaustively search all parameter combinations in a given grid to determine the best model.\n",
    "\n",
    "**Cross-validation:** Divide a dataset into k subsets and repeat the holdout method k times where a different subset is used as the holdout set in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "# This function clean_text preprocesses text by removing punctuation, converting to lowercase, splitting into tokens, removing stopwords, and stemming using the Porter stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# TF-IDF vectorization is applied to the text data using the TfidfVectorizer with the clean_text function as the analyzer. The resulting TF-IDF matrix is concatenated with additional features ('body_len' and 'punct%') to create X_tfidf_feat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...  8094  8095  8096  8097  \\\n",
       "0       128     4.7  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "1        49     4.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "2        62     3.2  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "3        28     7.1  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "4       135     4.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   8098  8099  8100  8101  8102  8103  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "X_count_feat.head()\n",
    "\n",
    "# Similarly, CountVectorizer is applied to the text data using the CountVectorizer with the clean_text function as the analyzer. The resulting count matrix is concatenated with additional features to create X_count_feat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GridSearchCV (Grid Search Cross-Validation) is a technique used for hyperparameter tuning in machine learning models. It is part of the scikit-learn library and provides an exhaustive search over a predefined grid of hyperparameters. Grid search is commonly used to find the optimal combination of hyperparameter values that yields the best model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_feat.columns = X_count_feat.columns.astype(str)\n",
    "X_tfidf_feat.columns = X_tfidf_feat.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.863390</td>\n",
       "      <td>0.820195</td>\n",
       "      <td>0.235477</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.975030</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.626752</td>\n",
       "      <td>0.634260</td>\n",
       "      <td>0.376012</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.979354</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.974132</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.380368</td>\n",
       "      <td>2.417373</td>\n",
       "      <td>0.255923</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.975741</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.973414</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.967870</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>0.271146</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.972515</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.315645</td>\n",
       "      <td>1.296192</td>\n",
       "      <td>0.190464</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       14.863390      0.820195         0.235477        0.035604   \n",
       "8       30.626752      0.634260         0.376012        0.024613   \n",
       "10      17.380368      2.417373         0.255923        0.063604   \n",
       "5       22.967870      0.275618         0.271146        0.012495   \n",
       "11      25.315645      1.296192         0.190464        0.002023   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "8               90                300   \n",
       "10            None                150   \n",
       "5               60                300   \n",
       "11            None                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.980251   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.977558   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.976661   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.977558   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.977558   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.978456           0.973944           0.967655   \n",
       "8            0.979354           0.973944           0.967655   \n",
       "10           0.975763           0.975741           0.967655   \n",
       "5            0.973968           0.974843           0.965858   \n",
       "11           0.974865           0.973944           0.965858   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.974843         0.975030        0.004350                1  \n",
       "8            0.972147         0.974132        0.004121                2  \n",
       "10           0.971249         0.973414        0.003445                3  \n",
       "5            0.970350         0.972515        0.004049                4  \n",
       "11           0.969452         0.972336        0.004160                5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for TfidfVectorizer\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# First, you specify the machine learning model you want to tune (e.g., RandomForestClassifier) and create a dictionary where the keys are hyperparameter names, and the values are lists of hyperparameter values to explore.\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "\n",
    "# You create a GridSearchCV object by passing the model, the hyperparameter grid, and other optional parameters like the number of cross-validation folds (cv) and the scoring metric (scoring). \n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "# You fit the GridSearchCV object to your training data. During this process, GridSearchCV performs an exhaustive search over all combinations of hyperparameters specified in the grid. For each combination, it trains the model using cross-validation and evaluates its performance using the specified scoring metric.\n",
    "gs_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5] # printing the top 5 models\n",
    "\n",
    "\n",
    "# This code initializes a random forest classifier and specifies hyperparameters for tuning (n_estimators and max_depth). Grid search with cross-validation (5-fold) is performed using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.202008</td>\n",
       "      <td>0.339279</td>\n",
       "      <td>0.420038</td>\n",
       "      <td>0.038618</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.973234</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.551421</td>\n",
       "      <td>1.414573</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.967655</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.223841</td>\n",
       "      <td>0.623316</td>\n",
       "      <td>0.231218</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.972157</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.907369</td>\n",
       "      <td>1.217214</td>\n",
       "      <td>0.277853</td>\n",
       "      <td>0.062739</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.972147</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.965858</td>\n",
       "      <td>0.971258</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.554027</td>\n",
       "      <td>0.356724</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.966757</td>\n",
       "      <td>0.969452</td>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       31.202008      0.339279         0.420038        0.038618   \n",
       "11      25.551421      1.414573         0.197908        0.004267   \n",
       "7       14.223841      0.623316         0.231218        0.012547   \n",
       "10      16.907369      1.217214         0.277853        0.062739   \n",
       "5       21.554027      0.356724         0.285362        0.018910   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "8               90                300   \n",
       "11            None                300   \n",
       "7               90                150   \n",
       "10            None                150   \n",
       "5               60                300   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.977558   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.976661   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.974865   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.976661   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}           0.975763   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "8            0.974865           0.972147           0.970350   \n",
       "11           0.973968           0.973944           0.967655   \n",
       "7            0.973968           0.973944           0.969452   \n",
       "10           0.973070           0.972147           0.968553   \n",
       "5            0.972172           0.971249           0.966757   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "8            0.971249         0.973234        0.002638                1  \n",
       "11           0.969452         0.972336        0.003292                2  \n",
       "7            0.968553         0.972157        0.002612                3  \n",
       "10           0.965858         0.971258        0.003735                4  \n",
       "5            0.969452         0.971079        0.002983                5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for CountVectorizer\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameter tuning is the process of finding the optimal hyperparameters for a machine learning model. \n",
    "\n",
    "# Hyperparameters are configuration settings external to the model that cannot be directly estimated from the data. They govern the learning process of the model and have a significant impact on its performance and generalization ability.\n",
    "\n",
    "# Number of Estimators (n_estimators): In ensemble methods like random forests or gradient boosting, this hyperparameter specifies the number of base learners (trees) in the ensemble.\n",
    "\n",
    "# Maximum Depth of Trees (max_depth): For tree-based models, such as decision trees, random forests, and gradient boosting, this hyperparameter limits the maximum depth of each tree in the ensemble, thereby controlling the complexity of the model.\n",
    "\n",
    "# Learning Rate: In gradient boosting algorithms like XGBoost and AdaBoost, the learning rate controls the step size at each iteration, affecting the speed of convergence and the influence of each base learner on the final ensemble.\n",
    "\n",
    "# Regularization Parameters: Hyperparameters like regularization strength (e.g., alpha in Lasso and Ridge regression) control the balance between fitting the training data and preventing overfitting by penalizing large coefficients.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
